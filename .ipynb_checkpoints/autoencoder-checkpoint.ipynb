{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "#import tensorflow_io as tfio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train/Train001/002.tif')\n",
    "im = im.resize((230,150))\n",
    "print(np.array(im).shape)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT=100\n",
    "IMG_WIDTH=100\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE=2\n",
    "\n",
    "train_set = 'UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train/*/*.tif'\n",
    "\n",
    "train_files = sorted(glob.glob(train_set))\n",
    "\n",
    "a = np.zeros((len(train_files),IMG_HEIGHT, IMG_WIDTH,1)).astype(np.float32)\n",
    "\n",
    "for idx, filename in enumerate(train_files):\n",
    "    im = Image.open(filename)\n",
    "    im = im.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "    a[idx,:,:,0] = np.array(im)/255.0\n",
    "    \n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "train_dataset  = tf.data.Dataset.from_tensor_slices((a, a)).shuffle(1000, \n",
    "                                                                    seed=42, \n",
    "                                                                    reshuffle_each_iteration=False).batch(BATCH_SIZE)\n",
    "print(len(list(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = 'UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/Test024/*'\n",
    "\n",
    "test_files = sorted(glob.glob(test_set))\n",
    "\n",
    "a = np.zeros((len(test_files),IMG_WIDTH, IMG_HEIGHT,1)).astype(np.float32)\n",
    "\n",
    "for idx,filename in enumerate(test_files):\n",
    "    im = Image.open(filename)\n",
    "    im = im.resize((IMG_WIDTH,IMG_HEIGHT))\n",
    "    a[idx,:,:,0] = np.array(im, dtype=np.float32)/255.0\n",
    "\n",
    "    \n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((a, a)).batch(1)\n",
    "print(len(list(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x,y in train_dataset.take(BATCH_SIZE):\n",
    "    print(x.shape, y.shape)\n",
    "    count = count + 1\n",
    "    if count > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for image,label in train_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    img = image[0][:,:,0]\n",
    "    lbl = label[0][:,:,0]\n",
    "    plt.imshow(img,cmap=plt.cm.gray, interpolation='nearest')\n",
    "    plt.show()\n",
    "    plt.imshow(lbl,cmap=plt.cm.gray, interpolation='nearest')\n",
    "    plt.show()\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "#with strategy.scope():\n",
    "conv_encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT,IMG_WIDTH,1)),\n",
    "                tf.keras.layers.Conv2D(32, \n",
    "                                       kernel_size=5, \n",
    "                                       activation='relu'\n",
    "                                      ),\n",
    "                tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "                tf.keras.layers.Conv2D(32, \n",
    "                                       kernel_size=5,\n",
    "                                       activation='relu'\n",
    "                                      ),\n",
    "                tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(1000)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "conv_decoder = tf.keras.Sequential(\n",
    "            [   \n",
    "                tf.keras.layers.Dense(22*22*32, \n",
    "                                      activation='relu'\n",
    "                                     ),\n",
    "                tf.keras.layers.Reshape(target_shape=(22,22,32)),\n",
    "                tf.keras.layers.UpSampling2D(2, interpolation='nearest'),\n",
    "                tf.keras.layers.Conv2DTranspose(32, \n",
    "                                                kernel_size=5, \n",
    "                                                activation=\"relu\"\n",
    "                                               ),\n",
    "                tf.keras.layers.UpSampling2D(2, interpolation='nearest'),\n",
    "                tf.keras.layers.Conv2DTranspose(1, \n",
    "                                                kernel_size=5, \n",
    "                                                activation=\"sigmoid\"\n",
    "                                               )\n",
    "            ]            \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = tf.keras.Input(shape=(IMG_HEIGHT,IMG_WIDTH,1))\n",
    "encoded = conv_encoder(image_input)\n",
    "print(encoded.shape)\n",
    "decoded = conv_decoder(encoded)\n",
    "print(decoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ae = tf.keras.Model(inputs=image_input, outputs=decoded)\n",
    "\n",
    "#conv_ae = tf.keras.Sequential([conv_encoder, conv_decoder])\n",
    "conv_ae.compile(loss=tf.keras.losses.MeanSquaredError(), \n",
    "        optimizer=tf.keras.optimizers.Adam(lr=1e-4, decay=1e-4),\n",
    "        metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv_ae(np.ones((1,100,100,1), dtype=np.float32))\n",
    "\n",
    "conv_ae.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = conv_ae.fit(train_dataset, epochs=30, validation_data=test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_loss(history):\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    print('plot image {}'.format(image.shape))\n",
    "    plt.imshow(image[:,:,0], cmap=plt.cm.gray, interpolation='nearest')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_reconstructions(model, images, n_images=5):\n",
    "    print('show reconstructions = {}'.format(images.shape))\n",
    "    reconstructions = model.predict(images[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 3, 5))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = list(test_dataset.take(1))[0]\n",
    "test_image = test_images[0]\n",
    "print(test_image.shape)\n",
    "show_reconstructions(conv_ae, test_image, n_images=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img, output, diff, H, threshold, counter):\n",
    "    #print('inside plot, imgshape {}'.format(img.shape))\n",
    "    fig, (ax0, ax1, ax2,ax3) = plt.subplots(ncols=4, figsize=(10, 5))\n",
    "    ax0.set_axis_off()\n",
    "    ax1.set_axis_off()\n",
    "    ax2.set_axis_off()\n",
    "    \n",
    "    ax0.set_title('input image')\n",
    "    ax1.set_title('reconstructed image')\n",
    "    ax2.set_title('diff ')\n",
    "    ax3.set_title('anomalies')\n",
    "    \n",
    "    ax0.imshow(img, cmap=plt.cm.gray, interpolation='nearest') \n",
    "    ax1.imshow(output, cmap=plt.cm.gray, interpolation='nearest')   \n",
    "    ax2.imshow(diff, cmap=plt.cm.viridis, vmin=0, vmax=255, interpolation='nearest')  \n",
    "    ax3.imshow(img, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    \n",
    "    x,y = np.where(H > threshold)\n",
    "    ax3.scatter(y,x,color='red',s=0.1) \n",
    "\n",
    "    plt.axis('off')\n",
    "    \n",
    "    fig.savefig('images/{:0>3d}.png'.format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4*255\n",
    "counter = 0;\n",
    "\n",
    "for image, _  in test_dataset:\n",
    "    counter = counter + 1\n",
    "    output = conv_ae.predict(image)\n",
    "    output = tf.multiply(output,255.)\n",
    "    img = tf.multiply(tf.cast(image, tf.float32), 255.)\n",
    "    diff = tf.subtract(output,img)\n",
    "    tmp = diff[0,:,:,0]\n",
    "    H = signal.convolve2d(tmp, np.ones((4,4)), mode='same')\n",
    "    plot(img[0,:,:,0], output[0,:,:,0], diff[0,:,:,0], H, threshold, counter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    " \n",
    "# Create the frames\n",
    "frames = []\n",
    "imgs = sorted(glob.glob('images/*.png'))\n",
    "print(imgs[:10])\n",
    "for i in imgs:\n",
    "    new_frame = Image.open(i)\n",
    "    frames.append(new_frame)\n",
    " \n",
    "# Save into a GIF file that loops forever\n",
    "frames[0].save('result.gif', format='GIF',\n",
    "               append_images=frames[1:],\n",
    "               save_all=True,\n",
    "               duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2env)",
   "language": "python",
   "name": "tf2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
